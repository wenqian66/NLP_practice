{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd89b895-1779-41a6-8ddc-ae70c5c004d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow import math\n",
    "import tensorflow.linalg as linalg\n",
    "import numpy as np\n",
    "\n",
    "# Setting random seeds\n",
    "numpy.random.seed(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dae27f4-cf5e-41f4-8cea-3f4c9f10ef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c7dacc3-c492-45c0-83c1-4b86a04aa73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a Siamese model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8af892c6-9ac6-4abf-bed6-977c1b93b873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">195,584</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sequential[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ sequential[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │    \u001b[38;5;34m195,584\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ sequential[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ sequential[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">195,584</span> (764.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m195,584\u001b[0m (764.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">195,584</span> (764.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m195,584\u001b[0m (764.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vocab_size = 500\n",
    "model_dimension = 128\n",
    "\n",
    "# Define the LSTM model\n",
    "LSTM = Sequential()\n",
    "LSTM.add(layers.Embedding(input_dim=vocab_size, output_dim=model_dimension))\n",
    "LSTM.add(layers.LSTM(units=model_dimension, return_sequences = True))\n",
    "LSTM.add(layers.AveragePooling1D(pool_size=2))\n",
    "LSTM.add(layers.Lambda(lambda x: math.l2_normalize(x)))\n",
    "\n",
    "input1 = layers.Input((None,))\n",
    "input2 = layers.Input((None,))\n",
    "\n",
    "# Concatenate two LSTMs together\n",
    "conc = layers.Concatenate(axis=1)((LSTM(input1), LSTM(input2)))\n",
    "    \n",
    "\n",
    "# Use the Parallel combinator to create a Siamese model out of the LSTM \n",
    "Siamese = Model(inputs=(input1, input2), outputs=conc)\n",
    "\n",
    "# Print the summary of the model\n",
    "Siamese.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fe69f58-69f4-4da2-900b-3d8f3a9b3b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Siamese model:\n",
      "\n",
      "Total layers: 4\n",
      "\n",
      "========\n",
      "Parallel.sublayers_0: <InputLayer name=input_layer, built=True>\n",
      "\n",
      "========\n",
      "Parallel.sublayers_1: <InputLayer name=input_layer_1, built=True>\n",
      "\n",
      "========\n",
      "Parallel.sublayers_2: <Sequential name=sequential, built=True>\n",
      "\n",
      "========\n",
      "Parallel.sublayers_3: <Concatenate name=concatenate, built=True>\n",
      "\n",
      "Detail of LSTM models:\n",
      "\n",
      "Total layers: 4\n",
      "\n",
      "========\n",
      "Serial.sublayers_0: <Embedding name=embedding, built=True>\n",
      "\n",
      "========\n",
      "Serial.sublayers_1: <LSTM name=lstm, built=True>\n",
      "\n",
      "========\n",
      "Serial.sublayers_2: <AveragePooling1D name=average_pooling1d, built=True>\n",
      "\n",
      "========\n",
      "Serial.sublayers_3: <Lambda name=lambda, built=True>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def show_layers(model, layer_prefix):\n",
    "    print(f\"Total layers: {len(model.layers)}\\n\")\n",
    "    for i in range(len(model.layers)):\n",
    "        print('========')\n",
    "        print(f'{layer_prefix}_{i}: {model.layers[i]}\\n')\n",
    "\n",
    "print('Siamese model:\\n')\n",
    "show_layers(Siamese, 'Parallel.sublayers')\n",
    "\n",
    "print('Detail of LSTM models:\\n')\n",
    "show_layers(LSTM, 'Serial.sublayers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717d81e6-0cb5-42eb-b596-40acc781406b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e917737-7f4d-4567-8c68-c31a0d3807f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modified Triplet Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1247c88f-a854-4fe9-89bc-34b5bd65d912",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1)Similarity Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3880fce4-70c4-4d7c-be65-5e80e40bba00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Inputs --\n",
      "v1 : [1. 2. 3.]\n",
      "v2 : [1.  2.  3.5] \n",
      "\n",
      "-- Outputs --\n",
      "cosine similarity : 0.9974086507360697\n"
     ]
    }
   ],
   "source": [
    "# Two vector example\n",
    "# Input data\n",
    "\n",
    "v1 = np.array([1, 2, 3], dtype=float)\n",
    "v2 = np.array([1, 2, 3.5], dtype=float)  # notice the 3rd element is offset by 0.5\n",
    "\n",
    "### START CODE HERE ###\n",
    "# Try modifying the vector v2 to see how it impacts the cosine similarity\n",
    "# v2 = v1                   # identical vector\n",
    "# v2 = v1 * -1              # opposite vector\n",
    "# v2 = np.array([0,-42,1], dtype=float)  # random example\n",
    "### END CODE HERE ###\n",
    "\n",
    "print(\"-- Inputs --\")\n",
    "print(\"v1 :\", v1)\n",
    "print(\"v2 :\", v2, \"\\n\")\n",
    "\n",
    "# Similarity score\n",
    "def cosine_similarity(v1, v2):\n",
    "    numerator = tf.math.reduce_sum(v1*v2) # takes the dot product between v1 and v2. Equivalent to np.dot(v1, v2)\n",
    "    denominator = tf.math.sqrt(tf.math.reduce_sum(v1*v1) * tf.math.reduce_sum(v2*v2))\n",
    "    return numerator / denominator\n",
    "\n",
    "print(\"-- Outputs --\")\n",
    "print(\"cosine similarity :\", cosine_similarity(v1, v2).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b701fdab-b4c4-4967-80fc-317435c32015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Inputs --\n",
      "v1 :\n",
      "[[ 1.  2.  3.]\n",
      " [ 9.  8.  7.]\n",
      " [-1. -4. -2.]\n",
      " [ 1. -7.  2.]]\n",
      "\n",
      "v2 :\n",
      "[[ 3.66317301  3.43055795 -0.09080058]\n",
      " [ 8.9832323   9.24267195  5.55982888]\n",
      " [-0.46897683 -3.78290295 -1.99141714]\n",
      " [ 0.65079958 -6.13394762  4.40607475]]\n",
      "\n",
      "Batch sizes match : True\n",
      "\n",
      "-- Outputs --\n",
      "Option 1 : loop\n",
      "[[ 0.54585293  0.85501183 -0.7479123  -0.55664368]\n",
      " [ 0.84056941  0.99077601 -0.88726101 -0.43233775]\n",
      " [-0.8705723  -0.80838804  0.99366415  0.69702587]\n",
      " [ 0.05645085 -0.11717703  0.43390414  0.94069221]]\n"
     ]
    }
   ],
   "source": [
    "# Two batches of vectors example\n",
    "# Input data\n",
    "\n",
    "v1_1 = np.array([1.0, 2.0, 3.0])\n",
    "v1_2 = np.array([9.0, 8.0, 7.0])\n",
    "v1_3 = np.array([-1.0, -4.0, -2.0])\n",
    "v1_4 = np.array([1.0, -7.0, 2.0])\n",
    "v1 = np.vstack([v1_1, v1_2, v1_3, v1_4])\n",
    "\n",
    "v2_1 = v1_1 + np.random.normal(0, 2, 3)  # add some noise to create approximate duplicate\n",
    "v2_2 = v1_2 + np.random.normal(0, 2, 3)\n",
    "v2_3 = v1_3 + np.random.normal(0, 2, 3)\n",
    "v2_4 = v1_4 + np.random.normal(0, 2, 3)\n",
    "v2 = np.vstack([v2_1, v2_2, v2_3, v2_4])\n",
    "\n",
    "print(\"-- Inputs --\")\n",
    "print(f\"v1 :\\n{v1}\\n\")\n",
    "print(f\"v2 :\\n{v2}\\n\")\n",
    "\n",
    "# Batch sizes must match\n",
    "b = len(v1)\n",
    "print(f\"Batch sizes match : {b == len(v2)}\\n\")\n",
    "\n",
    "# Similarity scores\n",
    "\n",
    "# Option 1 : nested loops and the cosine similarity function\n",
    "sim_1 = np.zeros([b, b])  # empty array to take similarity scores\n",
    "# Loop\n",
    "for row in range(0, sim_1.shape[0]):\n",
    "    for col in range(0, sim_1.shape[1]):\n",
    "        sim_1[row, col] = cosine_similarity(v2[row], v1[col]).numpy()\n",
    "\n",
    "print(\"-- Outputs --\")\n",
    "print(\"Option 1 : loop\")\n",
    "print(sim_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73b42408-841b-4d9b-a46d-fc8b9b758c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Outputs --\n",
      "Option 2 : vector normalization and dot product\n",
      "tf.Tensor(\n",
      "[[ 0.54585293  0.85501183 -0.7479123  -0.55664368]\n",
      " [ 0.84056941  0.99077601 -0.88726101 -0.43233775]\n",
      " [-0.8705723  -0.80838804  0.99366415  0.69702587]\n",
      " [ 0.05645085 -0.11717703  0.43390414  0.94069221]], shape=(4, 4), dtype=float64) \n",
      "\n",
      "Outputs are the same : True\n"
     ]
    }
   ],
   "source": [
    "# Option 2 : vector normalization and dot product\n",
    "def norm(x):\n",
    "    return tf.math.l2_normalize(x, axis=1) # use tensorflow built in normalization\n",
    "\n",
    "sim_2 = tf.linalg.matmul(norm(v2), norm(v1), transpose_b=True)\n",
    "\n",
    "print(\"-- Outputs --\")\n",
    "print(\"Option 2 : vector normalization and dot product\")\n",
    "print(sim_2, \"\\n\")\n",
    "\n",
    "# Check\n",
    "print(f\"Outputs are the same : {np.allclose(sim_1, sim_2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02edcdf3-33c1-4b49-8da5-a096035df512",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hard Negative Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08d305ee-623e-4b0b-a95e-f4a25a9d08de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Inputs --\n",
      "sim:\n",
      "[[ 0.9 -0.8  0.3 -0.5]\n",
      " [-0.4  0.5  0.1 -0.1]\n",
      " [ 0.3  0.1 -0.4 -0.8]\n",
      " [-0.5 -0.2 -0.7  0.5]]\n",
      "shape: (4, 4)\n",
      "\n",
      "sim_ap:\n",
      "[[ 0.9  0.   0.   0. ]\n",
      " [ 0.   0.5  0.   0. ]\n",
      " [ 0.   0.  -0.4  0. ]\n",
      " [ 0.   0.   0.   0.5]]\n",
      "\n",
      "sim_an:\n",
      "[[ 0.  -0.8  0.3 -0.5]\n",
      " [-0.4  0.   0.1 -0.1]\n",
      " [ 0.3  0.1  0.  -0.8]\n",
      " [-0.5 -0.2 -0.7  0. ]]\n",
      "\n",
      "-- Outputs --\n",
      "\n",
      "mean_neg:\n",
      "[[-0.33333333]\n",
      " [-0.13333333]\n",
      " [-0.13333333]\n",
      " [-0.46666667]]\n",
      "\n",
      "closest_neg :\n",
      "[[ 0.3]\n",
      " [ 0.1]\n",
      " [-0.8]\n",
      " [-0.2]]\n"
     ]
    }
   ],
   "source": [
    "# Hardcoded matrix of similarity scores\n",
    "sim_hardcoded = np.array(\n",
    "    [\n",
    "        [0.9, -0.8, 0.3, -0.5],\n",
    "        [-0.4, 0.5, 0.1, -0.1],\n",
    "        [0.3, 0.1, -0.4, -0.8],\n",
    "        [-0.5, -0.2, -0.7, 0.5],\n",
    "    ]\n",
    ")\n",
    "\n",
    "sim = sim_hardcoded\n",
    "\n",
    "### START CODE HERE ###\n",
    "# Try using different values for the matrix of similarity scores\n",
    "# sim = 2 * np.random.random_sample((b,b)) -1   # random similarity scores between -1 and 1\n",
    "# sim = sim_2                                   # the matrix calculated previously using vector normalization and dot product\n",
    "### END CODE HERE ###\n",
    "\n",
    "# Batch size\n",
    "b = sim.shape[0]\n",
    "\n",
    "print(\"-- Inputs --\")\n",
    "print(f\"sim:\")\n",
    "print(sim)\n",
    "print(f\"shape: {sim.shape}\\n\")\n",
    "\n",
    "# Positives\n",
    "# All the s(A,P) values : similarities from duplicate question pairs (aka Positives)\n",
    "# These are along the diagonal\n",
    "sim_ap = np.diag(sim)\n",
    "print(\"sim_ap:\")\n",
    "print(np.diag(sim_ap))\n",
    "\n",
    "\n",
    "# Negatives\n",
    "# all the s(A,N) values : similarities the non duplicate question pairs (aka Negatives)\n",
    "# These are in the off diagonals\n",
    "sim_an = sim - np.diag(sim_ap)\n",
    "print(\"\\nsim_an:\")\n",
    "print(sim_an)\n",
    "\n",
    "print(\"\\n-- Outputs --\")\n",
    "# Mean negative\n",
    "# Average of the s(A,N) values for each row\n",
    "mean_neg = np.sum(sim_an, axis=1, keepdims=True) / (b - 1)\n",
    "print(\"\\nmean_neg:\")\n",
    "print(mean_neg)\n",
    "\n",
    "# Closest negative\n",
    "# Max s(A,N) that is <= s(A,P) for each row\n",
    "mask_1 = np.identity(b) == 1            # mask to exclude the diagonal\n",
    "mask_2 = sim_an > sim_ap.reshape(b, 1)  # mask to exclude sim_an > sim_ap\n",
    "mask = mask_1 | mask_2\n",
    "sim_an_masked = np.copy(sim_an)         # create a copy to preserve sim_an\n",
    "sim_an_masked[mask] = -2\n",
    "\n",
    "closest_neg = np.max(sim_an_masked, axis=1, keepdims=True)\n",
    "print(\"\\nclosest_neg :\")\n",
    "print(closest_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6c7a9c-0eb4-465e-8ca5-8dadcdf941f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07c003bc-5ae9-4278-9064-3c239aa06ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Inputs --\n",
      "sim :\n",
      "[[ 0.9 -0.8  0.3 -0.5]\n",
      " [-0.4  0.5  0.1 -0.1]\n",
      " [ 0.3  0.1 -0.4 -0.8]\n",
      " [-0.5 -0.2 -0.7  0.5]]\n",
      "shape : (4, 4) \n",
      "\n",
      "sim_ap :\n",
      "tf.Tensor(\n",
      "[[ 0.9  0.   0.   0. ]\n",
      " [ 0.   0.5  0.   0. ]\n",
      " [ 0.   0.  -0.4  0. ]\n",
      " [ 0.   0.   0.   0.5]], shape=(4, 4), dtype=float64) \n",
      "\n",
      "sim_an :\n",
      "tf.Tensor(\n",
      "[[ 0.  -0.8  0.3 -0.5]\n",
      " [-0.4  0.   0.1 -0.1]\n",
      " [ 0.3  0.1  0.  -0.8]\n",
      " [-0.5 -0.2 -0.7  0. ]], shape=(4, 4), dtype=float64) \n",
      "\n",
      "-- Outputs --\n",
      "mean_neg :\n",
      "tf.Tensor([-0.33333333 -0.13333333 -0.13333333 -0.46666667], shape=(4,), dtype=float64) \n",
      "\n",
      "closest_neg :\n",
      "tf.Tensor([ 0.3  0.1 -0.8 -0.2], shape=(4,), dtype=float64) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hardcoded matrix of similarity scores\n",
    "sim_hardcoded = np.array(\n",
    "    [\n",
    "        [0.9, -0.8, 0.3, -0.5],\n",
    "        [-0.4, 0.5, 0.1, -0.1],\n",
    "        [0.3, 0.1, -0.4, -0.8],\n",
    "        [-0.5, -0.2, -0.7, 0.5],\n",
    "    ]\n",
    ")\n",
    "\n",
    "sim = sim_hardcoded\n",
    "\n",
    "### START CODE HERE ###\n",
    "# Try using different values for the matrix of similarity scores\n",
    "# sim = 2 * np.random.random_sample((b,b)) -1   # random similarity scores between -1 and 1\n",
    "# sim = sim_2                                   # the matrix calculated previously using vector normalization and dot product\n",
    "### END CODE HERE ###\n",
    "\n",
    "# Batch size\n",
    "b = sim.shape[0]\n",
    "\n",
    "print(\"-- Inputs --\")\n",
    "print(\"sim :\")\n",
    "print(sim)\n",
    "print(\"shape :\", sim.shape, \"\\n\")\n",
    "\n",
    "# Positives\n",
    "# All the s(A,P) values : similarities from duplicate question pairs (aka Positives)\n",
    "# These are along the diagonal\n",
    "sim_ap = tf.linalg.diag_part(sim) # this is just a 1D array of diagonal elements\n",
    "print(\"sim_ap :\")\n",
    "# tf.linalg.diag makes a diagonal matrix given an array\n",
    "print(tf.linalg.diag(sim_ap), \"\\n\")\n",
    "\n",
    "# Negatives\n",
    "# all the s(A,N) values : similarities the non duplicate question pairs (aka Negatives)\n",
    "# These are in the off diagonals\n",
    "sim_an = sim - tf.linalg.diag(sim_ap)\n",
    "print(\"sim_an :\")\n",
    "print(sim_an, \"\\n\")\n",
    "\n",
    "print(\"-- Outputs --\")\n",
    "# Mean negative\n",
    "# Average of the s(A,N) values for each row\n",
    "mean_neg = tf.math.reduce_sum(sim_an, axis=1) / (b - 1)\n",
    "print(\"mean_neg :\")\n",
    "print(mean_neg, \"\\n\")\n",
    "\n",
    "# Closest negative\n",
    "# Max s(A,N) that is <= s(A,P) for each row\n",
    "mask_1 = tf.eye(b) == 1            # mask to exclude the diagonal\n",
    "mask_2 = sim_an > tf.expand_dims(sim_ap, 1)  # mask to exclude sim_an > sim_ap\n",
    "mask = tf.cast(mask_1 | mask_2, tf.float64)\n",
    "sim_an_masked = sim_an - 2.0*mask\n",
    "\n",
    "closest_neg = tf.math.reduce_max(sim_an_masked, axis=1)\n",
    "print(\"closest_neg :\")\n",
    "print(closest_neg, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11701bcb-f04d-45c7-b4a9-3f12f9fd8aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3cb3521e-80d8-420d-8864-2f24c5f593f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1: [0.         0.         0.51666667 0.        ]\n",
      "\n",
      "Loss 2: [0. 0. 0. 0.]\n",
      "\n",
      "-- Outputs --\n",
      "Loss full :\n",
      "tf.Tensor([0.         0.         0.51666667 0.        ], shape=(4,), dtype=float64) \n",
      "\n",
      "Cost : 0.517\n"
     ]
    }
   ],
   "source": [
    "# Alpha margin\n",
    "alpha = 0.25\n",
    "\n",
    "# Modified triplet loss\n",
    "# Loss 1\n",
    "l_1 = tf.maximum(mean_neg - sim_ap + alpha, 0)\n",
    "print(f\"Loss 1: {l_1}\\n\")\n",
    "# Loss 2\n",
    "l_2 = tf.maximum(closest_neg - sim_ap + alpha, 0)\n",
    "print(f\"Loss 2: {l_2}\\n\")\n",
    "# Loss full<\n",
    "l_full = l_1 + l_2\n",
    "# Cost\n",
    "cost = tf.math.reduce_sum(l_full)\n",
    "\n",
    "print(\"-- Outputs --\")\n",
    "print(\"Loss full :\")\n",
    "print(l_full, \"\\n\")\n",
    "print(\"Cost :\", \"{:.3f}\".format(cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3595a203-dcf9-42a5-9709-f89bfed5686a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############Evaluate a Siamese model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25109b29-9d10-46f2-a5a0-bc5805ac9c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspecting the necessary elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c28218e6-7ff8-4fe7-a058-f5f50c89fdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q1 has shape: (512, 64) \n",
      "\n",
      "And it looks like this: \n",
      "\n",
      " [[ 32  38   4 ...   1   1   1]\n",
      " [ 30 156  78 ...   1   1   1]\n",
      " [ 32  38   4 ...   1   1   1]\n",
      " ...\n",
      " [ 32  33   4 ...   1   1   1]\n",
      " [ 30 156 317 ...   1   1   1]\n",
      " [ 30 156   6 ...   1   1   1]]\n",
      "\n",
      "\n",
      "q2 has shape: (512, 64) \n",
      "\n",
      "And looks like this: \n",
      "\n",
      " [[   30   156    78 ...     1     1     1]\n",
      " [  283   156    78 ...     1     1     1]\n",
      " [   32    38     4 ...     1     1     1]\n",
      " ...\n",
      " [   32    33     4 ...     1     1     1]\n",
      " [   30   156    78 ...     1     1     1]\n",
      " [   30   156 10596 ...     1     1     1]]\n",
      "\n",
      "\n",
      "y_test has shape: (512,) \n",
      "\n",
      "And looks like this: \n",
      "\n",
      " [0 1 1 0 0 0 0 1 0 1 1 0 0 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0 0 0 1 0 1 1 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 1 1 1 0 1 0 1 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0\n",
      " 0 0 0 1 0 0 1 1 0 0 0 1 0 1 1 0 1 0 0 0 1 0 1 0 0 0 0 1 1 1 0 1 0 1 1 0 0\n",
      " 0 1 0 0 1 1 0 0 1 0 1 0 0 1 1 0 1 0 0 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 1 1 0 1 1 1\n",
      " 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 1 0 1 0 0 0 0 1 0 0 1\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1\n",
      " 1 0 1 1 0 0 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 1 0 0\n",
      " 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0\n",
      " 0 0 1 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 1 0 0 1 1 1 0 1 1 0 1 0 1 1 1 0\n",
      " 1 1 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 1 0 1 1 1 0 0 0 1 0 1 1 1\n",
      " 0 1 0 0 0 0 0 0 0 1 1 1 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1\n",
      " 1 0 1 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "\n",
      "v1 has shape: (512, 128) \n",
      "\n",
      "And looks like this: \n",
      "\n",
      " [[ 0.01273625 -0.1496373  -0.01982759 ...  0.02205012 -0.00169148\n",
      "  -0.01598107]\n",
      " [-0.05592084  0.05792497 -0.02226785 ...  0.08156938 -0.02570007\n",
      "  -0.00503111]\n",
      " [ 0.05686752  0.0294889   0.04522024 ...  0.03141788 -0.08459651\n",
      "  -0.00968536]\n",
      " ...\n",
      " [ 0.15115018  0.17791134  0.02200656 ... -0.00851707  0.00571415\n",
      "  -0.00431194]\n",
      " [ 0.06995274  0.13110274  0.0202337  ... -0.00902792 -0.01221745\n",
      "   0.00505962]\n",
      " [-0.16043712 -0.11899089 -0.15950686 ...  0.06544471 -0.01208312\n",
      "  -0.01183368]]\n",
      "\n",
      "\n",
      "v2 has shape: (512, 128) \n",
      "\n",
      "And looks like this: \n",
      "\n",
      " [[ 0.07437647  0.02804951 -0.02974014 ...  0.02378932 -0.01696189\n",
      "  -0.01897198]\n",
      " [ 0.03270066  0.15122835 -0.02175895 ...  0.00517202 -0.14617395\n",
      "   0.00204823]\n",
      " [ 0.05635608  0.05454165  0.042222   ...  0.03831453 -0.05387777\n",
      "  -0.01447786]\n",
      " ...\n",
      " [ 0.04727105 -0.06748016  0.04194937 ...  0.07600753 -0.03072828\n",
      "   0.00400715]\n",
      " [ 0.00269269  0.15222628  0.01714724 ...  0.01482705 -0.0197884\n",
      "   0.01389528]\n",
      " [-0.15475044 -0.15718803 -0.14732707 ...  0.04299919 -0.01070975\n",
      "  -0.01318042]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q1 = np.load('./q1.npy')\n",
    "print(f'q1 has shape: {q1.shape} \\n\\nAnd it looks like this: \\n\\n {q1}\\n\\n')\n",
    "q2 = np.load('./q2.npy')\n",
    "print(f'q2 has shape: {q2.shape} \\n\\nAnd looks like this: \\n\\n {q2}\\n\\n')\n",
    "y_test = np.load('./y_test.npy')\n",
    "print(f'y_test has shape: {y_test.shape} \\n\\nAnd looks like this: \\n\\n {y_test}\\n\\n')\n",
    "v1 = np.load('./v1.npy')\n",
    "print(f'v1 has shape: {v1.shape} \\n\\nAnd looks like this: \\n\\n {v1}\\n\\n')\n",
    "v2 = np.load('./v2.npy')\n",
    "print(f'v2 has shape: {v2.shape} \\n\\nAnd looks like this: \\n\\n {v2}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b9874a9-8346-45bd-b69f-32a64bd7ba5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the accuracy\n",
    "accuracy = 0\n",
    "batch_size = 512 # Note: The max it can be is y_test.shape[0] i.e all the samples in test data\n",
    "threshold = 0.7 # You can play around with threshold and then see the change in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb1eebab-716f-47c9-bd6d-01900e34dd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(batch_size):        # Iterate over each element in the batch\n",
    "    d = math.reduce_sum(v1[j]*v2[j])# Compute the cosine similarity between the predictions as l2 normalized, ||v1[j]||==||v2[j]||==1 so only dot product is needed\n",
    "    res = d > threshold            # Determine if this value is greater than the threshold (if it is consider the two questions as the same)\n",
    "    accuracy += tf.cast(y_test[j] == res, tf.int32) # Compare against the actual target and if the prediction matches, add 1 to the accuracy\n",
    "\n",
    "accuracy = accuracy / batch_size   # Divide the accuracy by the number of processed elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fbaa218-efa8-46b6-82bf-8e7fe43cbc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is: 0.7421875\n"
     ]
    }
   ],
   "source": [
    "print(f'The accuracy of the model is: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f47b7e6-5e8a-4119-ac30-c61fd6e2a2e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e2d77c-87af-44e2-a6c5-0249c171a40f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dc453a-ad72-41e8-b35e-85625d2cc7f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb80e22-9ea7-4ae2-a624-9450bbf08928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cc4094-be6a-41ed-be54-61ecc954079e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a50d61-8852-49a8-8c8e-fc1963ff7ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222b4c14-9bb9-4d3b-a3b0-882b37cc3fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
